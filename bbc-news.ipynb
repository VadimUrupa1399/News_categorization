{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-15T17:20:29.709363Z","iopub.execute_input":"2022-06-15T17:20:29.709853Z","iopub.status.idle":"2022-06-15T17:20:33.439531Z","shell.execute_reply.started":"2022-06-15T17:20:29.709760Z","shell.execute_reply":"2022-06-15T17:20:33.438140Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# For data visualization\nimport seaborn as sns\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nfrom scipy.cluster.hierarchy import dendrogram, linkage\n\n# For NLP(text cleaning)\nimport nltk\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\n\n# For NLP(feature extraction)\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n\n# For dimension reduction\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import TruncatedSVD\n\n# For clustering\nfrom sklearn.cluster import KMeans\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.cluster import DBSCAN, AgglomerativeClustering\n\n# For file handeling operations\nimport os\nfrom glob import glob\nfrom tqdm import tqdm\n\n# To supress warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-06-15T17:24:36.984832Z","iopub.execute_input":"2022-06-15T17:24:36.985271Z","iopub.status.idle":"2022-06-15T17:24:39.904636Z","shell.execute_reply.started":"2022-06-15T17:24:36.985239Z","shell.execute_reply":"2022-06-15T17:24:39.903500Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"abs_filepaths = glob(\"../input/bbc-news-summary/BBC News Summary/News Articles/*/*.txt\")\n\n# Read it and store it in a list\nnews_articles = []\n\nfor abs_filepath in tqdm(abs_filepaths, colour='yellow'):\n    try:\n        # Open the file\n        f = open(abs_filepath,\"r\")\n        # Read the contents of the file\n        news_article = f.read()\n        # Append it in a list\n        news_articles.append(str(news_article))\n    except:\n        f = open(abs_filepath,'rb')\n        # Read the contents of the file\n        news_article = f.read()\n        # Append it in a list\n        news_articles.append(str(news_article))","metadata":{"execution":{"iopub.status.busy":"2022-06-15T17:25:57.845457Z","iopub.execute_input":"2022-06-15T17:25:57.845885Z","iopub.status.idle":"2022-06-15T17:26:08.612773Z","shell.execute_reply.started":"2022-06-15T17:25:57.845854Z","shell.execute_reply":"2022-06-15T17:26:08.611866Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"news_articles[0]","metadata":{"execution":{"iopub.status.busy":"2022-06-15T17:26:27.841963Z","iopub.execute_input":"2022-06-15T17:26:27.842372Z","iopub.status.idle":"2022-06-15T17:26:27.851937Z","shell.execute_reply.started":"2022-06-15T17:26:27.842326Z","shell.execute_reply":"2022-06-15T17:26:27.850868Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Create a stemmer object which will be used to stem all the words to its root\nps = PorterStemmer()","metadata":{"execution":{"iopub.status.busy":"2022-06-15T17:30:27.774039Z","iopub.execute_input":"2022-06-15T17:30:27.774520Z","iopub.status.idle":"2022-06-15T17:30:27.779205Z","shell.execute_reply.started":"2022-06-15T17:30:27.774482Z","shell.execute_reply":"2022-06-15T17:30:27.778170Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Data cleaning","metadata":{}},{"cell_type":"code","source":"# Empty list to store the clean text\nclean_articles = []\n\nfor article in tqdm(news_articles, colour='yellow'):\n    # Replace the end lines <\\n>\n    article = article.replace(\"\\\\n\",'')\n    \n    # Remove all excepth the alphabets\n    article = re.sub(\"[^a-zA-Z]\",' ', article)\n    \n    # Lower all the aplhabets\n    article = article.lower()\n    \n    # Split the article on spaces, returning a list of words\n    words = article.split()\n    \n   # Remove stopwords\n    clean_article = [ps.stem(word) for word in words if not word in stopwords.words(\"english\")]\n    \n    # Join clean words\n    clean_article = \" \".join(clean_article)\n    \n    # Append the tweet\n    clean_articles.append(clean_article)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T17:31:59.549292Z","iopub.execute_input":"2022-06-15T17:31:59.549975Z","iopub.status.idle":"2022-06-15T17:34:18.985824Z","shell.execute_reply.started":"2022-06-15T17:31:59.549937Z","shell.execute_reply":"2022-06-15T17:34:18.984806Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"clean_articles[0]","metadata":{"execution":{"iopub.status.busy":"2022-06-15T17:34:46.551057Z","iopub.execute_input":"2022-06-15T17:34:46.551444Z","iopub.status.idle":"2022-06-15T17:34:46.558706Z","shell.execute_reply.started":"2022-06-15T17:34:46.551414Z","shell.execute_reply":"2022-06-15T17:34:46.557566Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Text to vectors","metadata":{}},{"cell_type":"code","source":"# Initialize a vectorizer object\ntfidf = TfidfVectorizer()\n\n# Fit transform the clean article to create vectors\narticle_vectors = tfidf.fit_transform(clean_articles)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T17:38:05.398821Z","iopub.execute_input":"2022-06-15T17:38:05.399250Z","iopub.status.idle":"2022-06-15T17:38:06.194242Z","shell.execute_reply.started":"2022-06-15T17:38:05.399215Z","shell.execute_reply":"2022-06-15T17:38:06.193098Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"article_vectors","metadata":{"execution":{"iopub.status.busy":"2022-06-15T17:38:21.468748Z","iopub.execute_input":"2022-06-15T17:38:21.469145Z","iopub.status.idle":"2022-06-15T17:38:21.476689Z","shell.execute_reply.started":"2022-06-15T17:38:21.469115Z","shell.execute_reply":"2022-06-15T17:38:21.475698Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Dimentionality reduction","metadata":{}},{"cell_type":"code","source":"# Initialize a SVD object\nsvd = TruncatedSVD(2000)\n\n# Transform the data\nreduced_articles = svd.fit_transform(article_vectors)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T17:43:41.704618Z","iopub.execute_input":"2022-06-15T17:43:41.705043Z","iopub.status.idle":"2022-06-15T17:44:34.045258Z","shell.execute_reply.started":"2022-06-15T17:43:41.705012Z","shell.execute_reply":"2022-06-15T17:44:34.043755Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nplt.title(\"Explained Variance VS Number Of Features\")\nsns.lineplot(x=[i for i in range(2000)],y=np.cumsum(svd.explained_variance_ratio_))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-15T17:46:11.808970Z","iopub.execute_input":"2022-06-15T17:46:11.809901Z","iopub.status.idle":"2022-06-15T17:46:12.181909Z","shell.execute_reply.started":"2022-06-15T17:46:11.809850Z","shell.execute_reply":"2022-06-15T17:46:12.180700Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(\"Total Explained Variance is ---> \",np.cumsum(svd.explained_variance_ratio_)[-1])","metadata":{"execution":{"iopub.status.busy":"2022-06-15T17:47:02.898278Z","iopub.execute_input":"2022-06-15T17:47:02.898702Z","iopub.status.idle":"2022-06-15T17:47:02.904610Z","shell.execute_reply.started":"2022-06-15T17:47:02.898668Z","shell.execute_reply":"2022-06-15T17:47:02.903873Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Using Different clustering algorithms.","metadata":{}},{"cell_type":"code","source":"# To store sum  of squared distances for each number of cluster\nSSD = []\n\n# For each number of cluster k\nfor k in tqdm(range(2,10), colour='yellow'):\n    # Initialize a model\n    km = KMeans(n_clusters=k)\n    # Fit the model\n    km = km.fit(reduced_articles)\n    # Append the sum of squared distances\n    SSD.append(km.inertia_)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T17:49:37.435505Z","iopub.execute_input":"2022-06-15T17:49:37.436525Z","iopub.status.idle":"2022-06-15T17:50:03.206443Z","shell.execute_reply.started":"2022-06-15T17:49:37.436481Z","shell.execute_reply":"2022-06-15T17:50:03.205614Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Ploting an elbow plot (Num of clusters VS Sum of squared distances)\nplt.figure(figsize=(10,8))\nplt.title(\"Elbow Plot To Visually Select The Optimal K For Clustering\")\nplt.plot(range(2,10),SSD,'bx-')\nplt.xlabel(\"Number Of Cluster\")\nplt.ylabel(\"SSD\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-15T17:52:48.890953Z","iopub.execute_input":"2022-06-15T17:52:48.891588Z","iopub.status.idle":"2022-06-15T17:52:49.080035Z","shell.execute_reply.started":"2022-06-15T17:52:48.891529Z","shell.execute_reply":"2022-06-15T17:52:49.078950Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Initialize the model\nkmeans = KMeans(n_clusters=5)\n\n# Fit on the data\nkmeans.fit(reduced_articles)\n\n# Get the labels\nlabels = kmeans.labels_","metadata":{"execution":{"iopub.status.busy":"2022-06-15T17:55:52.678983Z","iopub.execute_input":"2022-06-15T17:55:52.679667Z","iopub.status.idle":"2022-06-15T17:55:55.572598Z","shell.execute_reply.started":"2022-06-15T17:55:52.679624Z","shell.execute_reply":"2022-06-15T17:55:55.571355Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Creating a dataframe of 2 dimensions:\n* News Articles\n* Labels","metadata":{}},{"cell_type":"code","source":"# Create a dictionary\ndf_dict = {\"news\":news_articles, 'labels_km':labels}\n\n# Convert to dataframe \ndf = pd.DataFrame(df_dict)\n\n# Print head\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-15T17:58:40.172478Z","iopub.execute_input":"2022-06-15T17:58:40.173403Z","iopub.status.idle":"2022-06-15T17:58:40.201568Z","shell.execute_reply.started":"2022-06-15T17:58:40.173326Z","shell.execute_reply":"2022-06-15T17:58:40.200195Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Applying T-SNE to visulize data in 2d","metadata":{}},{"cell_type":"code","source":"# Initlalize the tnse object\ntsne = TSNE(n_components=2)\n\n# Transform the data\ntsne_data = tsne.fit_transform(reduced_articles)\n\n# Convert to Dataframe\ntsne_df = pd.DataFrame(tsne_data, columns=['comp1','comp2'])","metadata":{"execution":{"iopub.status.busy":"2022-06-15T18:00:04.492141Z","iopub.execute_input":"2022-06-15T18:00:04.492952Z","iopub.status.idle":"2022-06-15T18:00:18.343488Z","shell.execute_reply.started":"2022-06-15T18:00:04.492905Z","shell.execute_reply":"2022-06-15T18:00:18.342177Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def tsne_viz(tsne_df,labels,label_col='',ax=False):\n    if not ax:\n        plt.figure(figsize=(15,9))\n        sns.scatterplot(x=tsne_df['comp1'],y=tsne_df['comp2'],hue=labels,palette='Set2')\n        plt.show()\n    else:\n        ax.set_title(f\"Visualising the clusters of {label_col} using TSNE\")\n        sns.scatterplot(x=tsne_df['comp1'],y=tsne_df['comp2'],hue=labels,palette='Set2',ax=ax)  \n","metadata":{"execution":{"iopub.status.busy":"2022-06-15T18:01:05.041650Z","iopub.execute_input":"2022-06-15T18:01:05.042102Z","iopub.status.idle":"2022-06-15T18:01:05.052113Z","shell.execute_reply.started":"2022-06-15T18:01:05.042064Z","shell.execute_reply":"2022-06-15T18:01:05.051018Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Visualize cluster","metadata":{}},{"cell_type":"code","source":"tsne_viz(tsne_df,df['labels_km'])","metadata":{"execution":{"iopub.status.busy":"2022-06-15T18:04:07.003783Z","iopub.execute_input":"2022-06-15T18:04:07.004254Z","iopub.status.idle":"2022-06-15T18:04:07.490397Z","shell.execute_reply.started":"2022-06-15T18:04:07.004216Z","shell.execute_reply":"2022-06-15T18:04:07.489352Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Gaussian mixture model","metadata":{}},{"cell_type":"code","source":"# Initialize the GMM object\ngmm = GaussianMixture(n_components=5)\n\n# Fit the model\ngmm.fit(reduced_articles)\n\n# Get the labels\nlabels_gmm = gmm.predict(reduced_articles)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T18:06:40.714520Z","iopub.execute_input":"2022-06-15T18:06:40.715018Z","iopub.status.idle":"2022-06-15T18:07:02.538032Z","shell.execute_reply.started":"2022-06-15T18:06:40.714984Z","shell.execute_reply":"2022-06-15T18:07:02.535387Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"df['labels_gmm'] = labels_gmm","metadata":{"execution":{"iopub.status.busy":"2022-06-15T18:07:06.036229Z","iopub.execute_input":"2022-06-15T18:07:06.036748Z","iopub.status.idle":"2022-06-15T18:07:06.046267Z","shell.execute_reply.started":"2022-06-15T18:07:06.036698Z","shell.execute_reply":"2022-06-15T18:07:06.044790Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"tsne_viz(tsne_df,df['labels_gmm'])","metadata":{"execution":{"iopub.status.busy":"2022-06-15T18:07:07.401898Z","iopub.execute_input":"2022-06-15T18:07:07.402365Z","iopub.status.idle":"2022-06-15T18:07:07.837003Z","shell.execute_reply.started":"2022-06-15T18:07:07.402329Z","shell.execute_reply":"2022-06-15T18:07:07.835511Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# Hierrchical cluatering","metadata":{}},{"cell_type":"code","source":"#Clustering with number of cluster as 5\n\nh_single = AgglomerativeClustering(n_clusters=5,affinity='euclidean', linkage='single')\nh_single.fit(reduced_articles)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T18:09:13.841814Z","iopub.execute_input":"2022-06-15T18:09:13.842312Z","iopub.status.idle":"2022-06-15T18:09:22.847515Z","shell.execute_reply.started":"2022-06-15T18:09:13.842273Z","shell.execute_reply":"2022-06-15T18:09:22.845903Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"df['labels_hier_single'] =  h_single.labels_","metadata":{"execution":{"iopub.status.busy":"2022-06-15T18:09:33.650289Z","iopub.execute_input":"2022-06-15T18:09:33.651271Z","iopub.status.idle":"2022-06-15T18:09:33.658506Z","shell.execute_reply.started":"2022-06-15T18:09:33.651203Z","shell.execute_reply":"2022-06-15T18:09:33.657217Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"tsne_viz(tsne_df,df['labels_hier_single'])","metadata":{"execution":{"iopub.status.busy":"2022-06-15T18:09:56.249114Z","iopub.execute_input":"2022-06-15T18:09:56.249599Z","iopub.status.idle":"2022-06-15T18:09:56.744927Z","shell.execute_reply.started":"2022-06-15T18:09:56.249560Z","shell.execute_reply":"2022-06-15T18:09:56.743753Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"# Average linkage method","metadata":{}},{"cell_type":"code","source":"#Clustering with number of cluster as 5\nh_average = AgglomerativeClustering(n_clusters=5,affinity='euclidean', linkage='average')\nh_average.fit(reduced_articles)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T18:12:01.779588Z","iopub.execute_input":"2022-06-15T18:12:01.780135Z","iopub.status.idle":"2022-06-15T18:12:06.322033Z","shell.execute_reply.started":"2022-06-15T18:12:01.780092Z","shell.execute_reply":"2022-06-15T18:12:06.319918Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"df['labels_hier_average'] =  h_average.labels_","metadata":{"execution":{"iopub.status.busy":"2022-06-15T18:12:20.863202Z","iopub.execute_input":"2022-06-15T18:12:20.864221Z","iopub.status.idle":"2022-06-15T18:12:20.872963Z","shell.execute_reply.started":"2022-06-15T18:12:20.864169Z","shell.execute_reply":"2022-06-15T18:12:20.871609Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"tsne_viz(tsne_df,df['labels_hier_average'])","metadata":{"execution":{"iopub.status.busy":"2022-06-15T18:12:39.601458Z","iopub.execute_input":"2022-06-15T18:12:39.602576Z","iopub.status.idle":"2022-06-15T18:12:40.021449Z","shell.execute_reply.started":"2022-06-15T18:12:39.602489Z","shell.execute_reply":"2022-06-15T18:12:40.016808Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"# Complete linkage method.","metadata":{}},{"cell_type":"code","source":"#Clustering with number of cluster as 5\nh_complete = AgglomerativeClustering(n_clusters=5,affinity='euclidean', linkage='complete')\nh_complete.fit(reduced_articles)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T18:13:57.757984Z","iopub.execute_input":"2022-06-15T18:13:57.758447Z","iopub.status.idle":"2022-06-15T18:14:02.072544Z","shell.execute_reply.started":"2022-06-15T18:13:57.758413Z","shell.execute_reply":"2022-06-15T18:14:02.071164Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"df['labels_hier_complete'] =  h_complete.labels_","metadata":{"execution":{"iopub.status.busy":"2022-06-15T18:14:18.326488Z","iopub.execute_input":"2022-06-15T18:14:18.326912Z","iopub.status.idle":"2022-06-15T18:14:18.333185Z","shell.execute_reply.started":"2022-06-15T18:14:18.326878Z","shell.execute_reply":"2022-06-15T18:14:18.331658Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"tsne_viz(tsne_df,df['labels_hier_complete'])","metadata":{"execution":{"iopub.status.busy":"2022-06-15T18:14:32.115520Z","iopub.execute_input":"2022-06-15T18:14:32.115936Z","iopub.status.idle":"2022-06-15T18:14:32.598744Z","shell.execute_reply.started":"2022-06-15T18:14:32.115904Z","shell.execute_reply":"2022-06-15T18:14:32.597624Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# DBScan clustering","metadata":{}},{"cell_type":"code","source":"# Initialize a DBSCAN object\ndbs = DBSCAN(eps = 1.25, min_samples=25)\n\n# Fir & Get the labels\nlabels_dbs = dbs.fit_predict(reduced_articles)","metadata":{"execution":{"iopub.status.busy":"2022-06-15T18:18:06.691372Z","iopub.execute_input":"2022-06-15T18:18:06.691862Z","iopub.status.idle":"2022-06-15T18:18:07.085278Z","shell.execute_reply.started":"2022-06-15T18:18:06.691817Z","shell.execute_reply":"2022-06-15T18:18:07.083692Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"df['labels_dbs'] = labels_dbs","metadata":{"execution":{"iopub.status.busy":"2022-06-15T18:18:18.314827Z","iopub.execute_input":"2022-06-15T18:18:18.315497Z","iopub.status.idle":"2022-06-15T18:18:18.326341Z","shell.execute_reply.started":"2022-06-15T18:18:18.315458Z","shell.execute_reply":"2022-06-15T18:18:18.324936Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"tsne_viz(tsne_df,df['labels_dbs'])","metadata":{"execution":{"iopub.status.busy":"2022-06-15T18:18:31.737659Z","iopub.execute_input":"2022-06-15T18:18:31.738118Z","iopub.status.idle":"2022-06-15T18:18:32.253680Z","shell.execute_reply.started":"2022-06-15T18:18:31.738083Z","shell.execute_reply":"2022-06-15T18:18:32.251898Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"# All clustering together.","metadata":{}},{"cell_type":"code","source":"fig,ax = plt.subplots(2,3,figsize=(30,15))\n\nrow = 0\ncol = 0\n\nfor column in df.columns[1:]:\n    tsne_viz(tsne_df,df[column],ax=ax[row,col],label_col=column)\n    \n    if col==2:\n        col=0\n        row+=1\n    else:\n        col+=1\n        \nplt.tight_layout(pad=3)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-15T18:19:06.049664Z","iopub.execute_input":"2022-06-15T18:19:06.050877Z","iopub.status.idle":"2022-06-15T18:19:08.866093Z","shell.execute_reply.started":"2022-06-15T18:19:06.050818Z","shell.execute_reply":"2022-06-15T18:19:08.864315Z"},"trusted":true},"execution_count":38,"outputs":[]}]}